[
["index.html", "Applied Environmental Statitics 1 Frontmatter", " Applied Environmental Statitics Rodney J. Dyer 1 Frontmatter This textbook was designed in support of the basic graduate level Applied Environmental Statistics course for the Center for Environmental Studies at Virginia Commonwealth University. T Build Date: Thu Mar 30 17:24:34 2017 The content of this text is modified, added to, and changed continually in support of this class. You are welcome to use the content of this book in its present form and you can provide feedback, comments, or suggestions for additions by contacting me at rjdyer@vcu.edu. This work will continue to be hosted online and continually updated as new approaches and applications become available. © 2017 by R.J. Dyer. This work is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License. Under this license, authorized individuals may copy, distribute, display and perform the work and make derivative works and remixes based on this text only if they give the original author credit (attribution). You are also free to distribute derivative works only under a license identical (“not more restrictive”) to the license that governs this original work. Dr. Rodney Dyer is a Professor and Director for the Center for Environmental Studies at Virginia Commonwealth University in Richmond, Virginia, USA. His research focuses on genetic connectivity and structure and how the environment influences both. More information on his research can be found at http://dyerlab.org. "],
["the-r-ecosystem.html", "2 The R Ecosystem 2.1 Getting R Configured 2.2 Libraries Used 2.3 The RStudio Environment", " 2 The R Ecosystem R is an open-source, community driven platform available for a wide variety of computer operating systems and is becoming a de facto standard in modern biological analyses. It is not a point-and-click interface, rather it is a rich analytical ecosystem that will make your research and scientific life more pleasurable. 2.1 Getting R Configured The grammar of the R language was derived from another system called S-Plus. S-Plus was a proprietary analysis platform developed by AT&amp;T and licenses were sold for its use, mostly in industry and education. Given the closed nature of the S-Plus platform, R was developed with the goal of creating an interpreter that could read grammar similar to S-Plus but be available to the larger research community. The use of R has increased dramatically due to its open nature and the ability of people to share code solutions with relatively little barriers. The main repository for R is located at the CRAN Repository, which is where you can download the latest version. It is in your best interests to make sure you update the underlying R system, changes are made continually (perhaps despite the outward appearance of the website). The current version of this book uses version 3.2. To get the correct version, open the page and there should be a link at the top for your particular computing platform. Download the appropriate version and install it following the instructions appropriate for your computer. 2.1.1 Packages The base R system comes with enough functionality to get you going. By default, there is only a limited amount of functionality in R, which is a great thing. You only load and use the packages that you intend to use. There are just too many packages to have them all loaded into memory at all times and there is such a broad range of packages, it is not likely you’d need more than a small fraction of the packages during the course of all your analyses. Once you have a package, you can tell R that you intend to use it by either library(package_name) or require(package_name) They are approximately equivalent, differing in only that the second one actually returns a TRUE or FALSE indicating the presence of that library on you machine. If you do not want to be mocked by other users of R, I would recommend the library version—there are situations where require will not do what you think you want it to do (even though it is a verb and should probably be the correct one to use grammatically). There are, at present, a few different places you can get packages. The packages can either be downloaded from these online repositories and installed into R or you can install them from within R itself. Again, I’ll prefer the latter as it is a bit more straightforward. 2.1.2 CRAN The main repository for packages is hosted by the r-project page itself. There are packages with solutions to analyses ranging from Approximate Bayesian Computation to Zhang &amp; Pilon’s approaches to characterizing climatic trends. The list of these packages is large and ever growing. It can be found on CRAN under the packages menu. To install a package from this repository, you use the function install.packages(&quot;thePackageName&quot;) You can see that R went to the CRAN mirror site (I use the rstudio one), downloaded the package, look for particular dependencies that that package may have and download them as well for you. It should install these packages for you and give you an affirmative message indicating it had done so. At times, there are some packages that are not available in binary form for all computer systems (the rgdal package is one that comes to mind for which we will provide a work around later) and the packages need to be compiled. This means that you need to have some additional tools and/or libraries on your machine to take the code, compile it, and link it together to make the package. In these cases, the internet and the documentation that the developer provide are key to your sanity. For packages on CRAN, you can also keep them updated to the latest version using the command: update.packages(ask=FALSE) I recommend using the ask=FALSE option on this one as it can be very tedious to respond to a “Y/N” question for each library you may need to update (there could be hundreds). 2.1.3 GitHub There are an increasing number of projects that are being developed either in the open source community or shared among a set of developers. These projects are often hosted on http://www.github.com where you can get access to the latest code updates. The packages that I develop are hosted on Github at (http://github.com/dyerlab) and only pushed to CRAN when I make major changes. To install packages from Github you need to install the devtools library from CRAN first install.packages(&quot;devtools&quot;) library(devtools) Then you need to use the devtools function install_github() to go grab it. To do so you need two separate pieces of information, the name of the developer who is creating the repository and the name of the repository it is contained within. For the gstudio package, the develop is dyerlab and the repository name is gstudio. If you are comfortable with git, you can also check out certain branches of development if you like with optional arguments to the install_github() function. Here is how you would install both the gstudio and popgraph libraries I use in this book. install_github(&quot;dyerlab/gstudio&quot;) install_github(&quot;dyerlab/popgraph&quot;) If you are starting to work with R and intend to compile packages, there are some tools that you will need to have on your machine. For Windows machines, there is an rtools download EXE that you can get. On OSX, you need to download the developers tools from Apple (available on the Application Store for free). In either case, the developer (if they care about their code being used by others) should provide sufficient documentation. If you are working on Windows, I do not know how that system (and never have used it for any prolonged period of time) so you’ll have to look to the internet on where to find compilers and other developer tools. In a way similar to that for the CRAN packages, you can update existing github packages using: library(devtools) update_packages() It will ask you if you really want to do this (which has three options: ‘Yup’, ‘No’, and ‘I forget’) and then proceed. 2.1.4 Bioconductor The last common location to find packages for R is on the Bioconductor site, a collection of software for bioinformatic analyses. To install from the bioconductor site you need to download their own installer as: source(&quot;http://bioconductor.org/biocLite.R&quot;) biocLite() And then to install packages you use biocLite(c(&quot;GenomicFeatures&quot;, &quot;AnnotationDbi&quot;)) There are no libraries used in this text from bioconductor as this text but if you shoudl do those kinds of analyses, it will be helpful to see what they have available. 2.1.5 Troublesome Packages Some packages provide a unique set of problems for getting them onto your computer. There are a variety of reasons for this and Google is your friend (though it would be easier if R was named something more unique than the 18th letter of the alphabet…). 2.1.5.1 RGDAL &amp; RGEOS Every time I upgrade in any significant way, two R libraries seem to raise their ugly heads and scream like a spoiled child—rgdal and rgeos. Why do these two have to be SOOOO much of a pain? Why can’t we have a auto build of a binary with all the options in it for OSX? Who knows? I always feel like I get the fuzzy end of the lollipop with these two. Here is my latest approach for getting them going. First you have to make sure you have the latest GDAL libraries. I used to get mine from Kyngchaos, just download the framework, install it, and then do some kind of long R CMD INSTALL dance, which seems to no longer work for me. I also tried installing from Ripley’s repository and found that: It was a version older than the one I already had on my machine, and You can’t install from that repository, there is a malformed header and the install.packages() function just barfs. Time to try something new. I typically stay away from the various installer frameworks out there on OSX to keep everything in Frameworks. But this time, I used MacPorts. You can find the latest version here. Here is how I got it to help me out. Download XCode from Apple, it is both free and has a lot of tools that make your life as a programmer easier. It is a big package and you’ll have to install the command line developer tools as well. You will be prompted on how to do this. Downloaded the version of macports for your OS, I’m currently on 10.11 and installed it with little problems. It takes a bit of time at the end of the installation because it is downloading a lot of information. Be patient. In the terminal, I updated it sudo ports -v selfupdate and again be patient, it is going to grab a lot of stuff from the internet. I then used it to install gdal as a unix library (rather than as a framework so it won’t be located in /Library/Frameworks) by sudo ports install gdal. There were a lot of dependencies for this one so it took a while. I then had R install rgdal as install.packages( rgdal, type=&quot;source&quot;) Worked like a charm. 2.2 Libraries Used This work requires several libraries that you may need to get from either CRAN or GitHub. The following if you run the following code, you should be up-to-date on the necessary packages used throughout this text. Table 2.1: R packages used in the examples shown in this book. Name Title devtools Tools to Make Developing R Packages Easier ggplot2 Create Elegant Data Visualisations Using the Grammar of Graphics 2.3 The RStudio Environment By itself, R can be used in the terminal or as the basic interface the installer provides. While both of these methods are sufficient for working in R, they are less than optimal (IMHO). I believe one of the most important tools you can use is a good IDE as it helps you organize and work with your data in ways that focus more on the outcome and less on the implementation. I’ve spent a lot of time in both Emacs and Vim and while they may be tools for the geek elite, RStudio has made me much more productive in terms of output per unit time. The RStudio IDE can be can be downloaded directly from (http://rstudio.org) and comes in varieties for desktops and servers. The packages are easy to install and contain all the instructions you need. If you run your own server, you can install it and do your analyses via a web interface that looks identical to the desktop client (in fact it is more similar than you perhaps know). The interface has four panes, two of which (the source code editor and the terminal output) you will work with the most often. The other panes have information on the history of your project, plot output, packages, help, command history, a list of all variables, and a file browser (in the image above, I have minimized the pane with the “Environment” and “History” tabs on it to make more room for the code editor). You can type in R commands in the terminal window and receive responses directly, just as normal. However, there are several alternative ways you can extract use R including: Code can be entered into a script file (ending in *.R) and run them directly by submitting that file to the R interpreter. This kind of file only has code (and comments) in it. A Markdown (*.Rmd) or LaTeX (*.Rwd) file that mixes code and non-code documenation together. This text is acutally written in RMarkdown and mixes together the word-processing parts and the analytical code in a single file. This is a very important and useful approach. If you are a serious user of R, you can use LaTeX or RMarkdown to make documents, slides, presentations, posters, etc. It is a versatile tool and one worth looking into, especially as it pertains to reproducible research (something we all need to strive for). "],
["data-types.html", "3 Data Types 3.1 Numeric Data Types 3.2 Characters 3.3 Factors 3.4 Logical Types", " 3 Data Types The data we work with comes in many forms—integers, stratum, categories, genotypes, etc.—all of which we need to be able to work with in our analyses. In this chapter, the basic data types we will commonly use in population genetic analyses. This section covers some of the basic types of data we will use in R. These include numbers, character, factors, and logical data types. We will also introduce the locus object from the gstudio library and see how it is just another data type that we can manipulate in R. The very first hurdle you need to get over is the oddness in the way in which R assigns values to variables. variable &lt;- value Yes that is a less-than and dash character. This is the assignment operator that historically has been used and it is the one that I will stick with. In some cases you can use the ‘=’ to assign variables instead but then it takes away the R-ness of R itself. For decision making, the equality operator (e.g., is this equal to that) is the double equals sign ‘==’. We will get into that below where we talk about logical types and later in decision making. If you are unaware of what type a particular variable may be, you can always use the type() function and R will tell you. class( variable ) R also has a pretty good help system built into itself. You can get help for any function by typing a question mark in front of the function name. This is a particularly awesome features because at the end of the help file, there is often examples of its usage, which are priceless. Here is the documentation for the ‘help’ function as given by: ?help There are also package vignettes available (for most packages you download) that provide additional information on the routines, data sets, and other items included in these packages. You can get a list of vignettes currently installed on your machine by: vignette() and vignettes for a particular package by passing the package name as an argument to the function itself. 3.1 Numeric Data Types The quantitative measurements we make are often numeric, in that they can be represented as as a number with a decimal component (think weight, height, latitude, soil moisture, ear wax viscosity, etc.). The most basic type of data in R, is the numeric type and represents both integers and floating point numbers (n.b., there is a strict integer data type but it is often only needed when interfacing with other C libraries and can for what we are doing be disregarded). Assigning a value to a variable is easy x &lt;- 3 x ## [1] 3 By default, R automatically outputs whole numbers numbers within decimal values appropriately. y &lt;- 22/7 y ## [1] 3.142857 If there is a mix of whole numbers and numbers with decimals together in a container such as c(x,y) ## [1] 3.000000 3.142857 then both are shown with decimals. The c() part here is a function that combines several data objects together into a vector and is very useful. In fact, the use of vectors are are central to working in R and functions almost all the functions we use on individual variables can also be applied to vectors. A word of caution should be made about numeric data types on any computer. Consider the following example. x &lt;- .3 / 3 x ## [1] 0.1 which is exactly what we’d expect. However, the way in which computers store decimal numbers plays off our notion of significant digits pretty well. Look what happens when I print out x but carry out the number of decimal places. print(x, digits=20) ## [1] 0.099999999999999991673 Not quite 0.1 is it? Not that far away from it but not exact. That is a general problem, not one that R has any more claim to than any other language and/or implementation. Does this matter much, probably not in the realm of the kinds of things we do in population genetics, it is just something that you should be aware of. You can make random sets of numeric data by using using functions describing various distributions. For example, some random numbers from the normal distribution are: rnorm(10) ## [1] -0.08448241 -0.22312177 -0.77401356 0.22492114 -0.03342704 ## [6] 0.10676400 1.39950794 0.95613612 -0.12562048 0.83592538 from the normal distribution with designated mean and standard deviation: rnorm(10,mean=42,sd=12) ## [1] 57.97373 35.70483 43.61200 44.18176 52.60986 32.56504 47.32318 ## [8] 27.27760 15.29521 47.75786 A poisson distribution with mean 2: rpois(10,lambda = 2) ## [1] 5 2 3 3 2 2 2 2 0 1 and the \\(\\chi^2\\) distribution with 1 degree of freedom: rchisq(10, df=1) ## [1] 0.21478484 4.20145662 3.02875383 1.17614936 4.95842930 0.37902981 ## [7] 0.23896871 1.51371147 0.02390482 1.32264330 There are several more distributions that if you need to access random numbers, quantiles, probability densities, and cumulative density values are available. 3.1.1 Coercion to Numeric All data types have the potential ability to take another variable and coerce it into their type. Some combinations make sense, and some do not. For example, if you load in a CSV data file using read_csv(), and at some point a stray non-numeric character was inserted into one of the cells on your spreadsheet, R will interpret the entire column as a character type rather than as a numeric type. This can be a very frustrating thing, spreadsheets should generally be considered evil as they do all kinds of stuff behind the scenes and make your life less awesome. Here is an example of coercion of some data that is initially defined as a set of characters x &lt;- c(&quot;42&quot;,&quot;99&quot;) x ## [1] &quot;42&quot; &quot;99&quot; and is coerced into a numeric type using the as.numeric() function. y &lt;- as.numeric( x ) y ## [1] 42 99 It is a built-in feature of the data types in R that they all have (or should have if someone is producing a new data type and is being courteous to their users) an as.X() function. This is where the data type decides if the values asked to be coerced are reasonable or if you need to be reminded that what you are asking is not possible. Here is an example where I try to coerce a non-numeric variable into a number. x &lt;- &quot;The night is dark and full of terrors...&quot; as.numeric( x ) ## Warning: NAs introduced by coercion ## [1] NA By default, the result should be NA (missing data/non-applicable) if you ask for things that are not possible. 3.2 Characters A collection of letters, number, and or punctuation is represented as a character data type. These are enclosed in either single or double quotes and are considered a single entity. For example, my name can be represented as: prof &lt;- &quot;Rodney J. Dyer&quot; prof ## [1] &quot;Rodney J. Dyer&quot; In R, character variables are considered to be a single entity, that is the entire prof variable is a single unit, not a collection of characters. This is in part due to the way in which vectors of variables are constructed in the language. For example, if you are looking at the length of the variable I assigned my name to you see length(prof) ## [1] 1 which shows that there is only one ‘character’ variable. If, as is often the case, you are interested in knowing how many characters are in the variable prof, then you use the nchar(prof) ## [1] 14 function instead. This returns the number of characters (even the non-printing ones like tabs and spaces. nchar(&quot; \\t &quot;) ## [1] 3 As all other data types, you can define a vector of character values using the c() function. x &lt;- &quot;I am&quot; y &lt;- &quot;not&quot; z &lt;- &#39;a looser&#39; terms &lt;- c(x,y,z) terms ## [1] &quot;I am&quot; &quot;not&quot; &quot;a looser&quot; And looking at the length() and nchar() of this you can see how these operations differ. length(terms) ## [1] 3 nchar(terms) ## [1] 4 3 8 3.2.1 Concatenation of Characters Another common use of characters is concatenating them into single sequences. Here we use the function paste() and can set the separators (or characters that are inserted between entities when we collapse vectors). Here is an example, entirely fictional and only provided for instructional purposes only. paste(terms, collapse=&quot; &quot;) ## [1] &quot;I am not a looser&quot; paste(x,z) ## [1] &quot;I am a looser&quot; paste(x,z,sep=&quot; not &quot;) ## [1] &quot;I am not a looser&quot; 3.2.2 Coercion to Characters A character data type is often the most basal type of data you can work with. For example, consider the case where you have named sample locations. These can be kept as a character data type or as a factor (see below). There are benefits and drawbacks to each representation of the same data (see below). By default (as of the version of R I am currently using when writing this book), if you use a function like read_table() to load in an external file, columns of character data will be treated as factors. This can be good behavior if all you are doing is loading in data and running an analysis, or it can be a total pain in the backside if you are doing more manipulative analyses. Here is an example of coercing a numeric type into a character type using the as.character() function. x &lt;- 42 x ## [1] 42 y &lt;- as.character(x) y ## [1] &quot;42&quot; 3.3 Factors A factor is a categorical data type. If you are coming from SAS, these are class variables. If you are not, then perhaps you can think of them as mutually exclusive classifications. For example, an sample may be assigned to one particular locale, one particular region, and one particular species. Across all the data you may have several species, regions, and locales. These are finite, and defined, sets of categories. One of the more common headaches encountered by people new to R is working with factor types and trying to add categories that are not already defined. Since factors are categorical, it is in your best interest to make sure you label them in as descriptive as a fashion as possible. You are not saving space or cutting down on computational time to take shortcuts and label the locale for Rancho Santa Maria as RSN or pop3d or 5. Our computers are fast and large enough, and our programmers are cleaver enough, to not have to rename our populations in numeric format to make them work (hello STRUCTURE I’m calling you out here). The only thing you have to loose by adopting a reasonable naming scheme is confusion in your output. To define a factor type, you use the function factor() and pass it a vector of values. region &lt;- c(&quot;North&quot;,&quot;North&quot;,&quot;South&quot;,&quot;East&quot;,&quot;East&quot;,&quot;South&quot;,&quot;West&quot;,&quot;West&quot;,&quot;West&quot;) region &lt;- factor( region ) region ## [1] North North South East East South West West West ## Levels: East North South West When you print out the values, it shows you all the levels present for the factor. If you have levels that are not present in your data set, when you define it, you can tell R to consider additional levels of this factor by passing the optional levels= argument as: region &lt;- factor( region, levels=c(&quot;North&quot;,&quot;South&quot;,&quot;East&quot;,&quot;West&quot;,&quot;Central&quot;)) region ## [1] North North South East East South West West West ## Levels: North South East West Central If you try to add a data point to a factor list that does not have the factor that you are adding, it will give you an error (or ‘barf’ as I like to say). region[1] &lt;- &quot;Bob&quot; ## Warning in `[&lt;-.factor`(`*tmp*`, 1, value = &quot;Bob&quot;): invalid factor level, ## NA generated Now, I have to admit that the Error message in its entirety, with its “[&lt;-.factor(*tmp*, 1, value = “Bob”)“` part is, perhaps, not the most informative. Agreed. However, the “invalid factor level” does tell you something useful. Unfortunately, the programmers that put in the error handling system in R did not quite adhere to the spirit of the “fail loudly” mantra. It is something you will have to get good at. Google is your friend, and if you post a questions to (http://stackoverflow.org) or the R user list without doing serious homework, put on your asbestos shorts! Unfortunately, the error above changed the first element of the region vector to NA (missing data). I’ll turn it back before we move too much further. region[1] &lt;- &quot;North&quot; Factors in R can be either unordered (as say locale may be since locale A is not &gt;, =, or &lt; locale B) or they may be ordered categories as in Small &lt; Medium &lt; Large &lt; X-Large. When you create the factor, you need to indicate if it is an ordered type (by default it is not). If the factors are ordered in some way, you can also create an ordination on the data. If you do not pass a levels= option to the factors() function, it will take the order in which they occur in data you pass to it. If you want to specify an order for the factors specifically, pass the optional levels= and they will be ordinated in the order given there. region &lt;- factor( region, ordered=TRUE, levels = c(&quot;West&quot;, &quot;North&quot;, &quot;South&quot;, &quot;East&quot;) ) region ## [1] North North South East East South West West West ## Levels: West &lt; North &lt; South &lt; East 3.3.1 Missing Levels in Factors There are times when you have a subset of data that do not have all the potential categories. subregion &lt;- region[ 3:9 ] subregion ## [1] South East East South West West West ## Levels: West &lt; North &lt; South &lt; East table( subregion ) ## subregion ## West North South East ## 3 0 2 2 3.4 Logical Types A logical type is either TRUE or FALSE, there is no in-between. It is common to use these types in making decisions (see if-else decisions) to check a specific condition being satisfied. To define logical variables you can either use the TRUE or FALSE directly canThrow &lt;- c(FALSE, TRUE, FALSE, FALSE, FALSE) canThrow ## [1] FALSE TRUE FALSE FALSE FALSE or can implement some logical condition stable &lt;- c( &quot;RGIII&quot; == 0, nchar(&quot;Marshawn&quot;) == 8) stable ## [1] FALSE TRUE on the variables. Notice here how each of the items is actually evaluated as to determine the truth of each expression. In the first case, the character is not equal to zero and in the second, the number of characters (what nchar() does) is indeed equal to 8 for the character string “Marshawn”. It is common to use logical types to serve as indices for vectors. Say for example, you have a vector of data that you want to select some subset from. data &lt;- rnorm(20) data ## [1] 0.34029068 1.26888537 0.10938657 -0.12999715 0.53900764 ## [6] 1.02001566 0.82721502 -1.17561430 0.17332534 -0.39280606 ## [11] -0.33172415 0.02456147 1.43902427 -0.58579205 -1.73160529 ## [16] -0.67444662 -0.91049637 -2.75375613 -1.01671200 0.28691854 Perhaps you are on interested in the non-negative values data[ data &gt; 0 ] ## [1] 0.34029068 1.26888537 0.10938657 0.53900764 1.02001566 0.82721502 ## [7] 0.17332534 0.02456147 1.43902427 0.28691854 If you look at the condition being passed to as the index data &gt; 0 ## [1] TRUE TRUE TRUE FALSE TRUE TRUE TRUE FALSE TRUE FALSE FALSE ## [12] TRUE TRUE FALSE FALSE FALSE FALSE FALSE FALSE TRUE you see that individually, each value in the data vector is being evaluated as a logical value, satisfying the condition that it is strictly greater than zero. When you pass that as indices to a vector it only shows the indices that are TRUE. You can coerce a value into a logical if you understand the rules. Numeric types that equal 0 (zero) are FALSE, always. Any non-zero value is considered TRUE. Here I use the modulus operator, %%, which provides the remainder of a division. 1:20 %% 2 ## [1] 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 which used as indices give us data[ (1:20 %% 2) &gt; 0 ] ## [1] 0.3402907 0.1093866 0.5390076 0.8272150 0.1733253 -0.3317241 ## [7] 1.4390243 -1.7316053 -0.9104964 -1.0167120 You can get as complicated in the creation of indices as you like, even using logical operators such as OR and AND. I leave that as an example for you to play with. "],
["r-data-containers.html", "4 R Data Containers 4.1 Vectors 4.2 Matrices 4.3 Lists 4.4 Data Frames", " 4 R Data Containers We almost never work with a single datum1, rather we keep lots of data. Moreover, the kinds of data are often heterogeneous, including categorical (Populations, Regions), continuous (coordinates, rainfall, elevation), imagry (hyperspectral, LiDAR), and perhaps even genetic. R has a very rich set of containers into which we can stuff our data as we work with it. Here these container types are examined and the restrictions and benefits associated with each type are explained. 4.1 Vectors We have already seen several examples of several vectors in action (see the introduction to Numeric data types for example). A vector of objects is simply a collection of them, often created using the c() function (c for combine). Vectorized data is restricted to having homogeneous data types—you cannot mix character and numeric types in the same vector. If you try to mix types, R will either coerce your data into a reasonable type x &lt;- c(1,2,3) x ## [1] 1 2 3 y &lt;- c(TRUE,TRUE,FALSE) y ## [1] TRUE TRUE FALSE z &lt;- c(&quot;I&quot;,&quot;am&quot;,&quot;not&quot;,&quot;a&quot;,&quot;looser&quot;) z ## [1] &quot;I&quot; &quot;am&quot; &quot;not&quot; &quot;a&quot; &quot;looser&quot; or coearce them into one type that is amenable to all the types of data that you have given it. In this example, a Logical, Character, Constant, and Function are combined resulting in a vector output of type Character. w &lt;- c(TRUE, &quot;1&quot;, pi, ls()) w ## [1] &quot;TRUE&quot; &quot;1&quot; &quot;3.14159265358979&quot; ## [4] &quot;canThrow&quot; &quot;data&quot; &quot;f&quot; ## [7] &quot;file&quot; &quot;files&quot; &quot;i&quot; ## [10] &quot;idx&quot; &quot;inst_pkgs&quot; &quot;item&quot; ## [13] &quot;libraries&quot; &quot;library&quot; &quot;pkgs&quot; ## [16] &quot;pkgs_df&quot; &quot;prof&quot; &quot;region&quot; ## [19] &quot;s&quot; &quot;stable&quot; &quot;subregion&quot; ## [22] &quot;terms&quot; &quot;title&quot; &quot;to_install&quot; ## [25] &quot;x&quot; &quot;y&quot; &quot;z&quot; class(w) ## [1] &quot;character&quot; Accessing elements within a vector are done using the square bracket [] notation. All indices (for vectors and matrices) start at 1 (not zero as is the case for some languages). Getting and setting the components within a vector are accomplished using numeric indices with the assignment operators just like we do for variables containing a single value. x ## [1] 1 2 3 x[1] &lt;- 2 x[3] &lt;- 1 x ## [1] 2 2 1 x[2] ## [1] 2 A common type of vector is that of a sequences. We use sequences all the time, to iterate through a list, to counting generations, etc. There are a few ways to generate sequences, depending upon the step sequence. For a sequence of whole numbers, the easiest is through the use of the colon operator. x &lt;- 1:6 x ## [1] 1 2 3 4 5 6 This provides a nice shorthand for getting the values X:Y from X to Y, inclusive. It is also possible to go backwards using this operator, counting down from X to Y as in: x &lt;- 5:2 x ## [1] 5 4 3 2 The only constraint here is that we are limited to a step size of 1.0. It is possible to use non-integers as the bounds, it will just count up by 1.0 each time. x &lt;- 3.2:8.4 x ## [1] 3.2 4.2 5.2 6.2 7.2 8.2 If you are interested in making a sequence with a step other than 1.0, you can use the seq() function. If you do not provide a step value, it defaults to 1.0. y &lt;- seq(1,6) y ## [1] 1 2 3 4 5 6 But if you do, it will use that instead. z &lt;- seq(1,20,by=2) z ## [1] 1 3 5 7 9 11 13 15 17 19 It is also possible to create a vector of objects as repetitions using the rep() (for repeat) function. rep(&quot;Beetlejuice&quot;,3) ## [1] &quot;Beetlejuice&quot; &quot;Beetlejuice&quot; &quot;Beetlejuice&quot; If you pass a vector of items to rep(), it can repeat these as either a vector being repeated (the default value) x &lt;- c(&quot;No&quot;,&quot;Free&quot;,&quot;Lunch&quot;) rep(x,time=3) ## [1] &quot;No&quot; &quot;Free&quot; &quot;Lunch&quot; &quot;No&quot; &quot;Free&quot; &quot;Lunch&quot; &quot;No&quot; &quot;Free&quot; &quot;Lunch&quot; or as each item in the vector repeated. rep(x,each=3) ## [1] &quot;No&quot; &quot;No&quot; &quot;No&quot; &quot;Free&quot; &quot;Free&quot; &quot;Free&quot; &quot;Lunch&quot; &quot;Lunch&quot; &quot;Lunch&quot; 4.2 Matrices A matrix is a 2- or higher dimensional container, most commonly used to store numeric data types. There are some libraries that use matrices in more than two dimensions (rows and columns and sheets), though you will not run across them too often. Here I restrict myself to only 2-dimensional matrices. You can define a matrix by giving it a set of values and an indication of the number of rows and columns you want. The easiest matrix to try is one with empty values: matrix(nrow=2, ncol=2) ## [,1] [,2] ## [1,] NA NA ## [2,] NA NA Perhaps more useful is one that is pre-populated with values. matrix(1:4, nrow=2 ) ## [,1] [,2] ## [1,] 1 3 ## [2,] 2 4 Notice that here, there were four entries and I only specified the number of rows required. By default the ‘filling-in’ of the matrix will proceed down column (by-column). In this example, we have the first column with the first two entries and the last two entries down the second column. If you want it to fill by row, you can pass the optional argument matrix(1:4, nrow=2, byrow=TRUE) ## [,1] [,2] ## [1,] 1 2 ## [2,] 3 4 and it will fill by-row. When filling matrices, the default size and the size of the data being added to the matrix are critical. For example, I can create a matrix as: Y &lt;- matrix(c(1,2,3,4,5,6),ncol=2,byrow=TRUE) Y ## [,1] [,2] ## [1,] 1 2 ## [2,] 3 4 ## [3,] 5 6 or X &lt;- matrix(c(1,2,3,4,5,6),nrow=2) X ## [,1] [,2] [,3] ## [1,] 1 3 5 ## [2,] 2 4 6 and both produce a similar matrix, only transposed. X == t(Y) ## [,1] [,2] [,3] ## [1,] TRUE TRUE TRUE ## [2,] TRUE TRUE TRUE In the example above, the number of rows (or columns) was a clean multiple of the number of entries. However, if it is not, R will fill in values. X &lt;- matrix(c(1,2,3,4,5,6),ncol=4, byrow=TRUE) ## Warning in matrix(c(1, 2, 3, 4, 5, 6), ncol = 4, byrow = TRUE): data length ## [6] is not a sub-multiple or multiple of the number of columns [4] Notice how you get a warning from the interpreter. But that does not stop it from filling in the remaining slots by starting over in the sequence of numbers you passed to it. X ## [,1] [,2] [,3] [,4] ## [1,] 1 2 3 4 ## [2,] 5 6 1 2 The dimensionality of a matrix (and data.frame as we will see shortly) is returned by the dim() function. This will provide the number of rows and columns as a vector. dim(X) ## [1] 2 4 Accessing elements to retrieve or set their values within a matrix is done using the square brackets just like for a vector but you need to give [row,col] indices. Again, these are 1-based so that X[1,3] ## [1] 3 is the entry in the 1st row and 3rd column. You can also use ‘slices’ through a matrix to get the rows X[1,] ## [1] 1 2 3 4 or columns X[,3] ## [1] 3 1 of data. Here you just omit the index for the entity you want to span. Notice that when you grab a slice, even if it is a column, is given as a vector. length(X[,3]) ## [1] 2 You can grab a sub-matrix using slices if you give a range (or sequence) of indices. X[,2:3] ## [,1] [,2] ## [1,] 2 3 ## [2,] 6 1 If you ask for values from a matrix that exceed its dimensions, R will give you an error. X[1,8] ## Error in X[1, 8] : subscript out of bounds ## Calls: &lt;Anonymous&gt; ... handle -&gt; withCallingHandlers -&gt; withVisible -&gt; eval -&gt; eval ## Execution halted There are a few cool extensions of the rep() function that can be used to create matrices as well. They are optional values that can be passed to the function. times=x: This is the default option that was occupied by the ‘3’ in the example above and represents the number of times that first argument will be repeated. each=x This will take each element in the first argument are repeat them each times. length.out=x: This make the result equal in length to x. In combination, these can be quite helpful. Here is an example using numeric sequences in which it is necessary to find the index of all entries in a 3x2 matrix. To make the indices, I bind two columns together using cbind(). There is a matching row binding function, denoted as rbind() (perhaps not so surprisingly). What is returned is a matrix indices &lt;- cbind( rep(1:2, each=3), rep(1:3,times=2), rep(5,length.out=6) ) indices ## [,1] [,2] [,3] ## [1,] 1 1 5 ## [2,] 1 2 5 ## [3,] 1 3 5 ## [4,] 2 1 5 ## [5,] 2 2 5 ## [6,] 2 3 5 4.3 Lists A list is a type of vector but is indexed by ‘keys’ rather than by numeric indices. Moreover, lists can contain heterogeneous types of data (e.g., values of different class), which is not possible in a vector type. For example, consider the list theList &lt;- list( x=seq(2,40, by=2), dog=LETTERS[1:5], hasStyle=logical(5) ) summary(theList) ## Length Class Mode ## x 20 -none- numeric ## dog 5 -none- character ## hasStyle 5 -none- logical which is defined with a numeric, a character, and a logical component. Each of these entries can be different in length as well as type. Once defined, the entries may be observed as: theList ## $x ## [1] 2 4 6 8 10 12 14 16 18 20 22 24 26 28 30 32 34 36 38 40 ## ## $dog ## [1] &quot;A&quot; &quot;B&quot; &quot;C&quot; &quot;D&quot; &quot;E&quot; ## ## $hasStyle ## [1] FALSE FALSE FALSE FALSE FALSE Once created, you can add variables to the list using the $-operator followed by the name of the key for the new entry. theList$my_favoriate_number &lt;- 2.9 + 3i or use double brackets and the name of the variable as a character string. theList[[&quot;lotto numbers&quot;]] &lt;- rpois(7,lambda=42) The keys currently in the list are given by the names() function names(theList) ## [1] &quot;x&quot; &quot;dog&quot; &quot;hasStyle&quot; ## [4] &quot;my_favoriate_number&quot; &quot;lotto numbers&quot; Getting and setting values within a list are done the same way using either the $-operator theList$x ## [1] 2 4 6 8 10 12 14 16 18 20 22 24 26 28 30 32 34 36 38 40 theList$x[2] &lt;- 42 theList$x ## [1] 2 42 6 8 10 12 14 16 18 20 22 24 26 28 30 32 34 36 38 40 or the double brackets theList[[&quot;x&quot;]] ## [1] 2 42 6 8 10 12 14 16 18 20 22 24 26 28 30 32 34 36 38 40 or using a numeric index, but that numeric index is looks to the results of names() to figure out which key to use. theList[[2]] ## [1] &quot;A&quot; &quot;B&quot; &quot;C&quot; &quot;D&quot; &quot;E&quot; The use of the double brackets in essence provides a direct link to the variable in the list whose name is second in the names() function (dog in this case). If you want to access elements within that variable, then you add a second set of brackets on after the double ones. theList[[1]][3] ## [1] 6 This deviates from the matrix approach as well as from how we access entries in a data.frame (described next). It is not a single square bracket with two indices, that gives you an error: theList[1,3] ## Error in theList[1, 3] : incorrect number of dimensions ## Calls: &lt;Anonymous&gt; ... handle -&gt; withCallingHandlers -&gt; withVisible -&gt; eval -&gt; eval ## Execution halted List are rather robust objects that allow you to store a wide variety of data types (including nested lists). Once you get the indexing scheme down, it they will provide nice solutions for many of your computational needs. 4.4 Data Frames The data.frame is the default data container in R. It is analogous to both a spreadsheet, at least in the way that I have used spreadsheets in the past, as well as a database. If you consider a single spreadsheet containing measurements and observations from your research, you may have many columns of data, each of which may be a different kind of data. There may be factors representing designations such as species, regions, populations, sex, flower color, etc. Other columns may contain numeric data types for items such as latitude, longitude, dbh, and nectar sugar content. You may also have specialized columns such as dates collected, genetic loci, and any other information you may be collecting. On a spreadsheet, each column has a unified data type, either quantified with a value or as a missing value, NA, in each row. Rows typically represent the sampling unit, perhaps individual or site, along which all of these various items have been measured or determined. A data.frame is similar to this, at least conceptually. You define a data.frame by designating the columns of data to be used. You do not need to define all of them, more can be added later. The values passed can be sequences, collections of values, or computed parameters. For example: df &lt;- data.frame( ID=1:5, Names=c(&quot;Bob&quot;,&quot;Alice&quot;,&quot;Vicki&quot;,&quot;John&quot;,&quot;Sarah&quot;), Score=100 - rpois(5,lambda=10)) df ## ID Names Score ## 1 1 Bob 88 ## 2 2 Alice 92 ## 3 3 Vicki 90 ## 4 4 John 96 ## 5 5 Sarah 78 You can see that each column is a unified type of data and each row is equivalent to a record. Additional data columns may be added to an existing data.frame as: df$Passed_Class &lt;- c(TRUE,TRUE,TRUE,FALSE,TRUE) Since we may have many (thousands?) of rows of observations, a summary() of the data.frame can provide a more compact description. summary(df) ## ID Names Score Passed_Class ## Min. :1 Alice:1 Min. :78.0 Mode :logical ## 1st Qu.:2 Bob :1 1st Qu.:88.0 FALSE:1 ## Median :3 John :1 Median :90.0 TRUE :4 ## Mean :3 Sarah:1 Mean :88.8 NA&#39;s :0 ## 3rd Qu.:4 Vicki:1 3rd Qu.:92.0 ## Max. :5 Max. :96.0 We can add columns of data to the data.frame after the fact using the $-operator to indicate the column name. Depending upon the data type, the summary will provide an overview of what is there. 4.4.1 Indexing Data Frames You can access individual items within a data.frame by numeric index such as: df[1,3] ## [1] 88 You can slide indices along rows (which return a new data.frame for you) df[1,] ## ID Names Score Passed_Class ## 1 1 Bob 88 TRUE or along columns (which give you a vector of data) df[,3] ## [1] 88 92 90 96 78 or use the $-operator as you did for the list data type to get direct access to a either all the data or a specific subset therein. df$Names[3] ## [1] Vicki ## Levels: Alice Bob John Sarah Vicki Indices are ordered just like for matrices, rows first then columns. You can also pass a set of indices such as: df[1:3,] ## ID Names Score Passed_Class ## 1 1 Bob 88 TRUE ## 2 2 Alice 92 TRUE ## 3 3 Vicki 90 TRUE It is also possible to use logical operators as indices. Here I select only those names in the data.frame whose score was &gt;90 and they passed popgen. df$Names[df$Score &gt; 90 &amp; df$Passed_Class==TRUE] ## [1] Alice ## Levels: Alice Bob John Sarah Vicki This is why data.frame objects are very database like. They can contain lots of data and you can extract from them subsets that you need to work on. This is a VERY important feature, one that is vital for reproducible research. Keep you data in one and only one place. The word data is plural, datum is singular↩ "],
["manipulating-data.html", "5 Manipulating Data 5.1 Data Import &amp; Export 5.2 Diving Into Data 5.3 Factor &amp; Character Data 5.4 Indexing 5.5 Sorting &amp; Ordering 5.6 Manipulating Data 5.7 Tabulating", " 5 Manipulating Data The sine qua non of of this course is instruction in how how to manipulate data. In this class activity, we will focus on some built-in data sets to allow you to work in R and get more keyboard time in RStudio. There will be a series of questions at the end of the lecture that will ask you to retrieve certain information from various data sets. 5.1 Data Import &amp; Export Raw data is imported into R using read.* functions. There are a wide variety of file formats available, most of which have a corresponding function (e.g., read.csv(), read.delim(), read.dcf(), etc.). For our purposes, we will focus on using comma separated files (*.CSV) as they are the most readily available and can be read by almost all editors and spreadsheet functions. On the lecture webpage, there is a file named iris.csv. Download this file and put it in the same directory as your RStudio session. If you do not know where this is, you can find it by asking R to get its current working directory as: getwd() ## [1] &quot;/Users/rodney/Documents/R/AppliedEnvironmentalStatistics&quot; The same information is also printed across the top of the “Files” pane in the RStudio interface (though it starts from your ‘home’ directory instead of the top of the file path). One way to easily open this location is to select the “Show Folder in New Window” menu item in the “More” menu on that same pane. It will open the folder you are looking at in the file system as a new window for you, then you can drag and drop things into it. Keep in mind that R is running in a specific location on your computer. This working directory is where it looks for stuff if you do not give a complete file path (e.g., ‘C:\\Users...’ or ‘/Users/…’ on winblows and mac, respectively). To load in a CSV file, we can use the function data &lt;- read.csv(&quot;file.csv&quot;) where at a bare minimum, we need to have the name of the file (in the example above it was ‘file.csv’). There are a lot of additional arguments you can pass to read.csv() including: header = TRUE: Does the file have a header row that gives the variable names? sep = &quot;,&quot;: What is the column separator. By default for CSV, it is a comma. quote = &quot;\\&quot;&quot;: Is there text that is quoted within the body of the document? dec = &quot;.&quot;: What is the decimal character? fill = TRUE: Do you want to fill in the empty data cells or do all rows of data have the same amount of data. comment.char = &quot;&quot;: Are there comments in the text? Additional options are available if you look at the help file as: ?read.csv Once you have read the file in (it will complain with an error message if it does not work), then you will have a data.frame object named data (from the example above, you should of course name it something more descriptive). \\(\\;\\) Saving materials in R is a bit easier. If you are needing to export the file back into a CSV format then you can use write.csv() (see ?write.csv for specifics and examples) and it will write the file as a text file. However, if you are only working in R with that file, you can save it as an R object without translating it back and forth through a CSV file. Using the example data from above, you could save the data.frame as an R data object using: save( data, file=&quot;mydata.rda&quot;) and it will save the object. Next time you need it, you can load it in using: load(&quot;mydata.rda&quot;) 5.2 Diving Into Data In this next section, we will walk through the example iris data set and highlight some of the ways that you can manipulate data.frame objects. If you have loaded in the data set as outlined above, we should be able to get a first look at it using the summary() function. summary(flowers) ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## Min. :4.300 Min. :2.000 Min. :1.000 Min. :0.100 ## 1st Qu.:5.100 1st Qu.:2.800 1st Qu.:1.600 1st Qu.:0.300 ## Median :5.800 Median :3.000 Median :4.350 Median :1.300 ## Mean :5.843 Mean :3.057 Mean :3.758 Mean :1.199 ## 3rd Qu.:6.400 3rd Qu.:3.300 3rd Qu.:5.100 3rd Qu.:1.800 ## Max. :7.900 Max. :4.400 Max. :6.900 Max. :2.500 ## Species ## setosa :50 ## versicolor:50 ## virginica :50 ## ## ## Each of the columns in the data.frame is named, the first four of which are numerical values and the last one is a species designation. 5.3 Factor &amp; Character Data Depending upon how you have set up your R session, the last column may be either a character type or a factor. By default, some builds of R turn all string characters into factors (a behavior I do not like because there are a lot of data types that I load in that are best defined as non-factors). In this data set though, it is probably best if the Species column were really a factor and not just a character data type. We will play with this data set a bit and we will use the Species as a defining category (i.e., a factor). flowers$Species &lt;- factor( flowers$Species ) summary(flowers) ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## Min. :4.300 Min. :2.000 Min. :1.000 Min. :0.100 ## 1st Qu.:5.100 1st Qu.:2.800 1st Qu.:1.600 1st Qu.:0.300 ## Median :5.800 Median :3.000 Median :4.350 Median :1.300 ## Mean :5.843 Mean :3.057 Mean :3.758 Mean :1.199 ## 3rd Qu.:6.400 3rd Qu.:3.300 3rd Qu.:5.100 3rd Qu.:1.800 ## Max. :7.900 Max. :4.400 Max. :6.900 Max. :2.500 ## Species ## setosa :50 ## versicolor:50 ## virginica :50 ## ## ## Notice in the output above how the factor column is tabulated by a count of the number of observations whereas the summary of the character data is just lumped all together. Also remember, if you do not specify the factors as ordered=TRUE then it will assume that they are categorical data without ordinal information. In this case, there is no reason to assume that one of these species types is greater than or less than another one so these are unordered factors. Conversely, if you have imported some data and it was automatically interpreted as factors, you can change a factor back to a character type by using the as.character() function. I find in my interactions with data, I use a lot more textual data than factors so I set the default up to not automatically translate it into factors, only doing so when I need to. In the example above, I replaced the original column of data with the factor version, though you may not need to do that. You can easily add another column of data to the data.frame giving it a new name. In the example below, I take the flowers$Species column and make a new one named Taxonomy by pasting the genus of the flowers onto it. flowers$Taxonomy &lt;- paste( &quot;Iris&quot;, flowers$Species ) summary(flowers) ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## Min. :4.300 Min. :2.000 Min. :1.000 Min. :0.100 ## 1st Qu.:5.100 1st Qu.:2.800 1st Qu.:1.600 1st Qu.:0.300 ## Median :5.800 Median :3.000 Median :4.350 Median :1.300 ## Mean :5.843 Mean :3.057 Mean :3.758 Mean :1.199 ## 3rd Qu.:6.400 3rd Qu.:3.300 3rd Qu.:5.100 3rd Qu.:1.800 ## Max. :7.900 Max. :4.400 Max. :6.900 Max. :2.500 ## Species Taxonomy ## setosa :50 Length:150 ## versicolor:50 Class :character ## virginica :50 Mode :character ## ## ## \\(\\;\\) 5.4 Indexing The normal workflow in R consists of loading data into your session, manipulating the data, and performing operations—statistical, summary, or graphical–on it (or some subset of it). Each element in the data.frame is indexed by the row and column number. The order of the columns is as shown or can be viewed using names(flowers) ## [1] &quot;Sepal.Length&quot; &quot;Sepal.Width&quot; &quot;Petal.Length&quot; &quot;Petal.Width&quot; ## [5] &quot;Species&quot; &quot;Taxonomy&quot; So if we wanted to access the Sepal.Width of 3\\(^{rd}\\) observation, we could use the numerical indices (where the “Sepal.Width” is the second name in this list): flowers[3,2] ## [1] 3.2 or by accessing the 3\\(^{rd}\\) element of the “Sepal.Width” vector. flowers$Sepal.Width[3] ## [1] 3.2 If you pull observations from a data.frame, you either get a new data.frame (if you include more than one column) df &lt;- flowers[,c(2,3,5)] class(df) ## [1] &quot;data.frame&quot; summary(df) ## Sepal.Width Petal.Length Species ## Min. :2.000 Min. :1.000 setosa :50 ## 1st Qu.:2.800 1st Qu.:1.600 versicolor:50 ## Median :3.000 Median :4.350 virginica :50 ## Mean :3.057 Mean :3.758 ## 3rd Qu.:3.300 3rd Qu.:5.100 ## Max. :4.400 Max. :6.900 or a vector of data (if you only have one column or any subset of one column). sepal_width &lt;- flowers$Sepal.Width length(sepal_width) ## [1] 150 class(sepal_width) ## [1] &quot;numeric&quot; sepal_width ## [1] 3.5 3.0 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 3.7 3.4 3.0 3.0 4.0 4.4 3.9 ## [18] 3.5 3.8 3.8 3.4 3.7 3.6 3.3 3.4 3.0 3.4 3.5 3.4 3.2 3.1 3.4 4.1 4.2 ## [35] 3.1 3.2 3.5 3.6 3.0 3.4 3.5 2.3 3.2 3.5 3.8 3.0 3.8 3.2 3.7 3.3 3.2 ## [52] 3.2 3.1 2.3 2.8 2.8 3.3 2.4 2.9 2.7 2.0 3.0 2.2 2.9 2.9 3.1 3.0 2.7 ## [69] 2.2 2.5 3.2 2.8 2.5 2.8 2.9 3.0 2.8 3.0 2.9 2.6 2.4 2.4 2.7 2.7 3.0 ## [86] 3.4 3.1 2.3 3.0 2.5 2.6 3.0 2.6 2.3 2.7 3.0 2.9 2.9 2.5 2.8 3.3 2.7 ## [103] 3.0 2.9 3.0 3.0 2.5 2.9 2.5 3.6 3.2 2.7 3.0 2.5 2.8 3.2 3.0 3.8 2.6 ## [120] 2.2 3.2 2.8 2.8 2.7 3.3 3.2 2.8 3.0 2.8 3.0 2.8 3.8 2.8 2.8 2.6 3.0 ## [137] 3.4 3.1 3.0 3.1 3.1 3.1 2.7 3.2 3.3 3.0 2.5 3.0 3.4 3.0 In addition to numerical values, you can also use logical statements to select subsets of your data. Here is an example of all the data whose flowers$Sepal.Width is less than 3.0cm and those that have sepals as large or bigger than 3.0cm. small_sepals &lt;- flowers[ flowers$Sepal.Width &lt; 3.0, ] big_sepals &lt;- flowers[ flowers$Sepal.Width &gt;= 3.0, ] summary( small_sepals ) ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## Min. :4.400 Min. :2.00 Min. :1.300 Min. :0.200 ## 1st Qu.:5.600 1st Qu.:2.50 1st Qu.:4.000 1st Qu.:1.200 ## Median :6.000 Median :2.70 Median :4.500 Median :1.400 ## Mean :5.953 Mean :2.64 Mean :4.509 Mean :1.449 ## 3rd Qu.:6.300 3rd Qu.:2.80 3rd Qu.:5.100 3rd Qu.:1.800 ## Max. :7.700 Max. :2.90 Max. :6.900 Max. :2.400 ## Species Taxonomy ## setosa : 2 Length:57 ## versicolor:34 Class :character ## virginica :21 Mode :character ## ## ## summary( big_sepals ) ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## Min. :4.300 Min. :3.000 Min. :1.000 Min. :0.100 ## 1st Qu.:5.000 1st Qu.:3.000 1st Qu.:1.500 1st Qu.:0.200 ## Median :5.600 Median :3.200 Median :1.900 Median :0.500 ## Mean :5.776 Mean :3.313 Mean :3.298 Mean :1.046 ## 3rd Qu.:6.500 3rd Qu.:3.500 3rd Qu.:5.200 3rd Qu.:1.800 ## Max. :7.900 Max. :4.400 Max. :6.700 Max. :2.500 ## Species Taxonomy ## setosa :48 Length:93 ## versicolor:16 Class :character ## virginica :29 Mode :character ## ## ## \\(\\;\\) There are two ways you can also merge data.frame objects. You can add data onto the bottom of the data.frame by using the rbind() function (row-binding). This requires that both data.frame objects have the same column names (and in the same order). all_sepals &lt;- rbind( small_sepals, big_sepals ) summary( all_sepals ) ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## Min. :4.300 Min. :2.000 Min. :1.000 Min. :0.100 ## 1st Qu.:5.100 1st Qu.:2.800 1st Qu.:1.600 1st Qu.:0.300 ## Median :5.800 Median :3.000 Median :4.350 Median :1.300 ## Mean :5.843 Mean :3.057 Mean :3.758 Mean :1.199 ## 3rd Qu.:6.400 3rd Qu.:3.300 3rd Qu.:5.100 3rd Qu.:1.800 ## Max. :7.900 Max. :4.400 Max. :6.900 Max. :2.500 ## Species Taxonomy ## setosa :50 Length:150 ## versicolor:50 Class :character ## virginica :50 Mode :character ## ## ## You can also merge together two data.frames that have a common column index. This may be necessary for cases where you have different kinds of observations that need to be merged into a single data.frame. Here is an example where I have some data on my sampling sites sites &lt;- data.frame( Site=c(&quot;Olympia&quot;,&quot;Richmond&quot;), Latitude=c(47.0379,37.5407), Longitude=c(122.9007,77.4360) ) sites ## Site Latitude Longitude ## 1 Olympia 47.0379 122.9007 ## 2 Richmond 37.5407 77.4360 and another set of data that has some observations on samples taken from each site. data &lt;- data.frame( Site=c(&quot;Olympia&quot;,&quot;Olympia&quot;,&quot;Olympia&quot;,&quot;Richmond&quot;,&quot;Richmond&quot;)) data$Measurement &lt;- c(12,22,35,56,46) data ## Site Measurement ## 1 Olympia 12 ## 2 Olympia 22 ## 3 Olympia 35 ## 4 Richmond 56 ## 5 Richmond 46 If I wanted to merge these two data.frame objects into a single one, incorporating each of the columns of data in both, I would df &lt;- merge( sites, data ) df ## Site Latitude Longitude Measurement ## 1 Olympia 47.0379 122.9007 12 ## 2 Olympia 47.0379 122.9007 22 ## 3 Olympia 47.0379 122.9007 35 ## 4 Richmond 37.5407 77.4360 56 ## 5 Richmond 37.5407 77.4360 46 Here the merge() function looks for a column that has the same name in both data.frame objects. In this case it was “Site”. It then uses that as an index to merge both together into a new object. 5.5 Sorting &amp; Ordering The order in which rows of observations are in the data.frame is determined by their placement in the original file. If you look at the data, it seems to be sorted by flowers$Species but nothing after that. head(flowers) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species Taxonomy ## 1 5.1 3.5 1.4 0.2 setosa Iris setosa ## 2 4.9 3.0 1.4 0.2 setosa Iris setosa ## 3 4.7 3.2 1.3 0.2 setosa Iris setosa ## 4 4.6 3.1 1.5 0.2 setosa Iris setosa ## 5 5.0 3.6 1.4 0.2 setosa Iris setosa ## 6 5.4 3.9 1.7 0.4 setosa Iris setosa You can sort the whole data.frame by asking for a copy of it with a specific order based upon the columns. Here I will re-assign the data.frame but this time ordered by flowers$Sepal.Length. flowers &lt;- flowers[ order(flowers$Sepal.Length), ] head(flowers) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species Taxonomy ## 14 4.3 3.0 1.1 0.1 setosa Iris setosa ## 9 4.4 2.9 1.4 0.2 setosa Iris setosa ## 39 4.4 3.0 1.3 0.2 setosa Iris setosa ## 43 4.4 3.2 1.3 0.2 setosa Iris setosa ## 42 4.5 2.3 1.3 0.3 setosa Iris setosa ## 4 4.6 3.1 1.5 0.2 setosa Iris setosa Note the row indices (the column on the far left), they indicate the original order in which the observations were put into the data.frame. The smallest sepal length in the data set was originally the 14\\(^{th}\\) observation. You see from the example above that the addition of new columns to a data.frame result in them being put on the right-hand side data.frame (e.g., flowers$Taxonomy is the last column of the output). If you want to rearrange the columns of the data.frame, you do so by manually re-arranging the indices on those columns. For example, if I wanted to make the numerical data the last four columns instead of the first two, I would specify it as: flowers &lt;- flowers[ , c(6,5,1,2,3,4) ] summary(flowers) ## Taxonomy Species Sepal.Length Sepal.Width ## Length:150 setosa :50 Min. :4.300 Min. :2.000 ## Class :character versicolor:50 1st Qu.:5.100 1st Qu.:2.800 ## Mode :character virginica :50 Median :5.800 Median :3.000 ## Mean :5.843 Mean :3.057 ## 3rd Qu.:6.400 3rd Qu.:3.300 ## Max. :7.900 Max. :4.400 ## Petal.Length Petal.Width ## Min. :1.000 Min. :0.100 ## 1st Qu.:1.600 1st Qu.:0.300 ## Median :4.350 Median :1.300 ## Mean :3.758 Mean :1.199 ## 3rd Qu.:5.100 3rd Qu.:1.800 ## Max. :6.900 Max. :2.500 5.6 Manipulating Data As we saw above, you can change data either in-place or by adding new columns (and you could also drop columns by reordering them and just not include all the columns in the column indices). You can also perform operations on columns of data, again either in-place, as an additional column, or not connected at all with the data.frame. To do it in-place, you simply re-assign the values after the calculation. For example, here is how I would subtract the average “Sepal.Length” from all the observations. ave_sepal_length &lt;- mean( flowers$Sepal.Length ) standardized_sepal_lengths &lt;- flowers$Sepal.Length - ave_sepal_length summary( standardized_sepal_lengths ) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## -1.54300 -0.74330 -0.04333 0.00000 0.55670 2.05700 Which should have a mean of zero, right? \\(\\;\\) 5.7 Tabulating We can finish up this exploration of the iris data set by doing some summaries. One of the main strengths of R is that it is a functional language. This may not mean much to you now, but in the long run you will find that you can perform opertions on large data sets by merging together cleaver use of indices and the application of one or more functions. Consider the case where we are trying to find the mean for each of the three species. Proceedurally, we must do the following general steps: Go through each row of the data and figure out which species we are looking at. Add the length of this observation to a tally variable, one for each species. Count how many observations of each species we have in the data.frame. Divide the approporiate tally variable by the number of observations. Return or print out the results. Not a trivial thing to do. If you were going to to this literally, you would have to set up three tally variables, three observation count variables, and then do a loop and run through all the observations making decisions on which observation is which and where to add the tally and count. Fortunately for us, this is not that difficult of an issue in R for the following two reasons: 1. We have a function mean() that estimates the mean of a set of variables. 2. We have a factor varaible in flowers that differentiates between species. As such we can then ask R to estimate the mean in “Sepal.Length” by “Species” using mean_sepal_length &lt;- by( flowers$Sepal.Length, flowers$Species, mean) mean_sepal_length ## flowers$Species: setosa ## [1] 5.006 ## -------------------------------------------------------- ## flowers$Species: versicolor ## [1] 5.936 ## -------------------------------------------------------- ## flowers$Species: virginica ## [1] 6.588 If you read this literally, it says, “Wit Sepal Length, partition the data by Species and pass it to the function mean”. This shorthand is important in that it highlights the flexibility and utility of applying functions to our data. With a few keystrokes, we can accomplish a lot of computational progress! You could find these values by slicing as: # literally grab the mean of all sepal lengths WHERE species is identical to X mean_setosa &lt;- mean( flowers$Sepal.Length[ flowers$Species == &quot;setosa&quot; ] ) mean_versicolor &lt;- mean( flowers$Sepal.Length[ flowers$Species == &quot;versicolor&quot; ] ) mean_virginica &lt;- mean( flowers$Sepal.Length[ flowers$Species == &quot;virginica&quot; ] ) mean_sepal_lengths_long &lt;- c(setosa=mean_setosa, versicolor=mean_versicolor, virginica=mean_virginica ) mean_sepal_lengths_long ## setosa versicolor virginica ## 5.006 5.936 6.588 But it sure does look like a lot more code to write! In general, we should strive to keep our code as easy to understand as possible. In the end, you will be reading your own code and you must be able to easily understand it at some random time in the future. For this to happen, you really need to clear on what you are trying to do. \\(\\;\\) "],
["rmarkdown.html", "6 RMarkdown 6.1 Markdown 6.2 Marking up Text 6.3 Inserting R Code Chunks 6.4 Variables in Text", " 6 RMarkdown Writing code and the associated text around the analyses and your data is an odd job that munges together some programming skills, a lot of copy-and-paste, saving images, menu jujitsu (Insert \\(\\to\\) Image \\(\\to\\) From Computer…), etc. One of the things that we should strive to do is to minimize the amount of stoooopid work that we have to do in our daily lives, right? Markdown is a way to create textual output that can be magically turned into many types of output. In this section, we start looking at some markdown examples that integrate our data, analysis code, and output into a single document that makes our lives suck just a little bit less . 6.1 Markdown Consider the case where you are making a report using a word processor like Word or Pages. The most basic part of that document is the actual text that you use in the document. Certain parts of that text represent different ‘landmarks’ in the paper, titles and headers are typically of a different typeface, images are saved from a different program, etc. If you are to include code, results from analyses, images of output and other stuff that isn’t directly typed into the document, you must do that outside the word processor and somehow insert it into that document. This moving between the processor where you are typing the actual content and other external sources of content and mushing them together is pretty much common place. In addition to this work flow, at the end of the day you spend a lot of time working on presentation style. Images and tables moving between page breaks, manually renumbering equations and figures, trying to figure out where captions and figure legends go, and at the end of the day, making sure the statistical work that you did stays in sync with how you are presenting the output in the document. One change in your analysis may percolate to many changes throughout the document that you must manually fix. Perhaps more importantly though, at the end of the day, you are left with a single Word document. What if you want to take those analyses and make a presentation, poster, website, docbook, or pdf out of it? What if you want to make automatic reports on continuous data sources? You have to do this over and over again manually because you are stuck using a word processor that only makes one kind of output. Markdown was designed as a way to create content and display it in many different formats, from the same kind of source. It is a very simple way of creating content that allows you to present it in a wide variety of output formats. Markdown is, at a bare minimum, just text. Anyone can write it using any editor you like. For our purposes, RStudio is a nice editor and the one we will use. A markdown file is saved with the extension .Rmd (or .rmd). To make a markdown document in RStudio, select File \\(\\to\\) New File \\(\\to\\) RMarkdown… and you will be give a dialog of potential types of markdown templates to start from that look like the following image. The main categories on the left are: Document: This is the main category of documents you can prepare. Presentation: You can make html and pdf presentations using markdown. Shiny: Shiny is a way to make interactive graphics and data ‘dashboards’ in R that are hosted on a web server (free ones are available or you can host one on your own server if you have one). Templates: This is where specific themed templates are stored for any of the above type of markdown document. For the time being, lets stick with documents and keep the default setting for HTML. As noted in the dialog, we can switch to the other formats later without a problem and HTML output is perhaps the most versatile for using while we are creating the document. 6.2 Marking up Text In a markdown document, it is all text. As such, we need to do typographic things like make headings, bold, italics, etc. Markdown accomplishes these by using symbols around the textual items you are changing. Here are some examples as an image (if I typed them into this document, which is RMarkdown, they would be converted so you wouldn’t see them). There are a lot more markup options (footnotes, links, citations, etc.) that can be found by selecting Help \\(\\to\\) Markdown Quick Reference in RStudio. 6.3 Inserting R Code Chunks In markdown, code is contained with what is called a ‘chunk’. This chunk can be a block of code (encompassing some kind of data analysis or the creation of some kind of graphical output) or it can be a bit that is inserted inline with your text (e.g., something like P &lt; 0.0323 may be computed and inserted on the fly). You can insert a chunk of code by selecting the R option from the Insert menu just above the editor (see below). There is also a keyboard shortcut that can be used to insert a chunk without going to the menu (and it is much faster), though they are platform dependent. Once you insert a chunk, RStudio provides a highlighted section within which you can insert your code. Everything within the chunk itself is going to be interpreted just as if it were written in a normal R script. 6.3.1 Chunk Options There are several options you can specify that determine the behavior of the chunk. These are inserted within the curly brackets at the top of the chunk. Some of the more common ones include: eval=TRUE/FALSE Determine if the code is actually run. Perhaps you are just demonstrating the code. echo=TRUE/FALSE Determine if the code is shown in the output. We can hide a lot of code ‘behind the scenes’ in our documents and only provide the output as appropriate (e.g., you’d never show the code for the analysis in your manuscript but it can be embedded in the document directly and serve up the results when you compile it). fig.cap=&quot;&quot; Caption for figures and tables. warning=TRUE/FALSE, message=TRUE/FALSE, error=TRUE/FALSE Toggle the visibility of warnings, messages, and errors in the output in the final document. There are many additional options that can be found in the documentation for knitr (the package that actually does the magic of turning the markdown into something else) at http://yihui.name/knitr/options/ 6.4 Variables in Text Variables and values from the R code in your document can be inserted into the text as well. To do this, you enclose the R code you are using in between a backslash plus the letter r (“r&quot;) and a trailing backslash (&quot;”). Here is an image of an example and the output: My all time favorite number is 9 and always has been. "]
]
